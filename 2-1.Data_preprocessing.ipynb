{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Data_preprocessing.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"lUKpcaDVvtIk","colab_type":"code","outputId":"a0712da9-d996-461c-ad2d-66c2f8cc2ae9","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import sqlite3\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.font_manager as fm\n","import re\n","\n","font_name = fm.FontProperties( fname = '../7주차/NLP/malgun.ttf' ).get_name()\n","print( font_name )\n","matplotlib.rc( 'font' , family = font_name )\n","\n","pd.set_option( 'display.max_rows' , 10000 )\n","pd.set_option( 'display.max_columns' , 10000 )\n","pd.set_option( 'display.width' , 10000 )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Malgun Gothic\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"froxN0NXvtIq","colab_type":"text"},"source":["## 파일 불러오기"]},{"cell_type":"code","metadata":{"id":"TwpLSP47vtIr","colab_type":"code","colab":{}},"source":["dbname = 'database/insta_comment.db'\n","sql = 'SELECT * FROM split_hashtag'\n","\n","with sqlite3.connect(dbname) as connection:\n","    cur = connection.cursor()\n","    raw_data = cur.execute(sql).fetchall()\n","    raw_data = pd.DataFrame(raw_data )\n","    \n","select_data = raw_data[[0,1,2,3,6,7]]\n","\n","column_names = ['idx_text' , 'user_id' , 'date' , 'comments' , 'like' , 'keyword']\n","select_data = pd.DataFrame(select_data.values , columns = column_names)\n","raw_data = select_data.copy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TMTNlwUSvtIu","colab_type":"text"},"source":["## 광고성글 제거하기"]},{"cell_type":"code","metadata":{"id":"hX779DWUvtIv","colab_type":"code","outputId":"e0ad31ff-2b26-4b29-ba6d-65c300f39499","colab":{}},"source":["import time\n","# # ['7361412120','23044404754','8512094273','6676042994','2278759108','3175636431','1446151047','5411851063','5531172020','2201236007','7162103099','254913460','1428703068','1186990437']\n","fake_id = [7361412120,23044404754,8512094273,6676042994,2278759108,3175636431,1446151047,5411851063,5531172020,2201236007,7162103099,254913460,1428703068,1186990437]\n","id_ = raw_data['user_id'].unique()\n","\n","fake_id = set(fake_id)\n","print(len(fake_id))\n","id_ = set(id_)\n","print(len(id_))\n","\n","pure_id = id_ - fake_id\n","print(len(pure_id))\n","\n","copy_data = raw_data.copy()\n","copy_data['pure_user'] = copy_data['user_id'].isin(pure_id)\n","data_r_fake_id = copy_data.loc[copy_data['pure_user'] == True ]\n","data = data_r_fake_id.copy()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["14\n","349487\n","349473\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zFXk1djevtIy","colab_type":"text"},"source":["## 코멘트만 가져오기"]},{"cell_type":"code","metadata":{"id":"HhiEYAPWvtIz","colab_type":"code","colab":{}},"source":["import re\n","\n","def get_hash(data):\n","    reg = re.compile('[\\#][ㄱ-힇a-zA-Z0-9]+')\n","    try:\n","        res = reg.findall(data)\n","        txt = ''\n","        for i in res:\n","            txt += i\n","            txt += ' '\n","        res = txt\n","    except:\n","        res = ''\n","        \n","    return res\n","        \n","def get_comments( data ):\n","    reg = re.compile('[\\#][ㄱ-힇a-zA-Z0-9]+')\n","    \n","    res = reg.sub('', data).strip()\n","      \n","#     except:\n","#         res = ''\n","    \n","        \n","    return res\n","data['pure_comment'] = data['comments'].apply(get_comments)\n","data['hash'] = data['comments'].apply(get_hash)\n","output_data = data.loc[data['pure_comment'] != '' ]\n","output_data.reset_index(drop=True , inplace = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CJJVe6U7vtI1","colab_type":"text"},"source":["## 키워드 색인하기"]},{"cell_type":"code","metadata":{"id":"6VQKngWvvtI2","colab_type":"code","outputId":"40197b72-ae1f-4fc8-f967-5b731073a511","colab":{}},"source":["keyword = raw_data['keyword'].unique() \n","\n","keyword\n","# '라이스버거', '허니버터', '과일소주', '맛스타그램', '시카고피자', '쉑쉑', '방어', '콩불', '훠궈',\n","#  '감바스', '핫도그', '마라롱샤', '곤약젤리', '마라탕', '탄탄면', '마약김밥', '밥', '모찌'"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['라이스버거', '슈니발렌', '허니버터', '과일소주', '푸파', '푸드파이터', '맛스타그램', '먹스타그램',\n","       '시카고피자', '쉑쉑', '딸기모찌', '방어', '팟타이', '콩불', '훠궈', '후쿠오카함바그', '감바스',\n","       '핫도그', '프랑스가정식', '미국가정식', '푸드스타그램', '마라롱샤', '일본가정식', '대만카스테라',\n","       '곤약젤리', '펑리수', '마라탕', '나시고랭', '불닭', '냉동삼겹살', '푸드트럭', '탄탄면', '마약김밥',\n","       '밥', '말차', '모찌'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"ytvVJZInvtI5","colab_type":"code","colab":{}},"source":["food_F = data.loc[(data['keyword'] == '맛스타그램') | (data['keyword'] == '푸드스타그램')|(data['keyword'] == '푸파')|(data['keyword'] == '먹스타그램')]\n","output_data = food_F[['user_id','date' , 'pure_comment' , 'hash', 'keyword']]\n","output_data.reset_index(drop = True , inplace = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NAKy_9SZvtI8","colab_type":"text"},"source":["### tokenize화 하기 특정 코멘트"]},{"cell_type":"code","metadata":{"id":"mblQmJ6wvtI8","colab_type":"code","colab":{}},"source":["from konlpy.tag import *\n","# h = Hannanum()\n","okt = Okt() # okt 사용\n","# mecab = Mecab()\n","# ko = Komoran()\n","\n","def token_han(text):\n","    token_ = h.pos(text)\n","    return token_\n","\n","\n","def token_okt(text):\n","    token_ = okt.pos(text)\n","    return token_\n","\n","\n","def token_mecab(text):\n","    token_ = mecab.pos(text)\n","    return token_\n","\n","def token_komoran(text):\n","    token_ = ko.pos(text)\n","    return token_\n","\n","\n","def token_okt(text):\n","    token_ = okt.pos(text)\n","    return token_\n","\n","def token_okt_selected(text):\n","    token_ = okt.pos(text)\n","    res = []\n","    \n","    for word , pos in token_:\n","        if pos in ['Noun' , 'Adjective' , 'Verb' , 'Adverb']:\n","            res.append(word)\n","        \n","    return res"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tJNY0cUvtI_","colab_type":"code","colab":{}},"source":["s_data = output_data[['date','pure_comment','hash','keyword']]\n","s_data = s_data.loc[ s_data['pure_comment'] != '' ].reset_index(drop = True )\n","\n","def token_okt(text):\n","    token_ = okt.pos(text)\n","    return token_\n","\n","sample_token = s_data.sample(frac = 0.01 , random_state = 3)\n","\n","sample_token['tokenize'] = sample_token['pure_comment'].apply(token_okt)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LpJgGHL2vtJB","colab_type":"text"},"source":["## 토큰화 하고 특정 형태소 찾기"]},{"cell_type":"code","metadata":{"id":"KRGk3bpkvtJC","colab_type":"code","outputId":"914a8f69-1f41-44b7-a5fe-2828e05f5c50","colab":{}},"source":["\n","    \n","    for word , pos in token_:\n","        if pos in ['Noun' , 'Adjective' , 'Verb' , 'Adverb']:\n","            res.append(word)\n","        \n","    return res\n","\n","def comment_selected(text):\n","    token_ = okt.pos(text)\n","    res = ''\n","    \n","    for word , pos in token_:\n","        if pos in ['Noun' , 'Adjective' , 'Verb' , 'Adverb']:\n","            word = word + ' '\n","            res += word\n","        \n","    return res\n","\n","sample_token['tokenize_selected'] = sample_token['pure_comment'].apply(token_okt_selected)\n","sample_token['selected_comment'] = sample_token['pure_comment'].apply(comment_selected)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/Users/joonam/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/Users/joonam/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"CHcJqDYNvtJF","colab_type":"text"},"source":["## 해시태그 tokenize"]},{"cell_type":"code","metadata":{"id":"hSBiOII1vtJF","colab_type":"code","outputId":"08ee1980-a0f0-4c2b-ae5e-764404425f2e","colab":{}},"source":["badword=['맛스타그램','먹스타그램','푸파','푸드파이터','foodfighter','맛스타그램' ,'일상','데일리','핌스타그램','인스타그램'\n","        ,'foodstagram','nice','선팔','맞팔','먹스타','먹스타 ','맛스타 ','맛스타','hotelrestaurant','foodstagram ','식신'\n","         ,'먹스타그램' , '맛스타그램', '데일리' ,'맞팔','선팔','좋아요','진짜','냠냠', '대존맛',\n","            '맛집추천','음식','너무','술스타그램','koreanfood','럽스타그램','여행스타그램',\n","            '요리스타그램','좋아요반사','ㅋㅋ','일상스타그램','food','첫줄','f4f',\n","            '함께','사진','일상','맛집','일상스타그램','푸드스타그램','감사합니다','daily',\n","            'ㅎㅎ','먹방','존맛','stagram','반사','어제','입니다','어제','카페','있는',\n","            '스타그램','소통','같이','오늘도','이제','오늘은','소통해요','그리고','인친','follow',\n","            '소통팔로우','맛은','ㅋㅋㅋ','ㅋㅋㅋㅋ','#오랜만에','주말','l4l','instagood','ootd','맛스타','fff','아주','먹고','먹어','해요',\n","            '셀카','그냥','ie','셀피','selfie','#얼스타그램','셀스타그램','인스타푸드','얼','like4like','투어','porn','foodporn','좋반',\n","            '먹으니','해서','하면','ㅠㅠ','likeforlike','먹스타먹스타','환영','다들','안녕','갑자기','insta','그램','gram']\n","badword.sort(key=len, reverse=True)\n","badword\n","\n","def nice_hash(text):\n","    text = text.replace('#','')\n","    for bw in badword:\n","        if bw in text:\n","            text = text.replace(bw ,'')\n","            \n","    return text\n","\n","sample_token['nice_hash'] = sample_token['hash'].apply(nice_hash)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/Users/joonam/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OPmxiZsBvtJI","colab_type":"code","colab":{}},"source":["final_data = sample_data['selected_comment' , 'nice_hash' , 'keyword']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5F6BRhIvtJK","colab_type":"code","colab":{}},"source":["final_data.to_csv('preprocessed_data.csv')"],"execution_count":0,"outputs":[]}]}